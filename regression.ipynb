{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LENOVO\\\\Desktop\\\\PYTHON\\\\VERİ BİLİMİ'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\LENOVO\\\\Desktop\\\\PYTHON\\\\VERİ BİLİMİ\\\\bootcamp_ödev_finans_verisi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: researchpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from researchpy) (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from researchpy) (0.23.4)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from researchpy) (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from researchpy) (1.19.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->researchpy) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->researchpy) (2018.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas->researchpy) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "!pip install researchpy\n",
    "import researchpy as rp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verisetine İlk Bakışı Atmamızı Sağlayacak Olan Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information():\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def info(self):\n",
    "        print(data.info())\n",
    "        \n",
    "    \n",
    "    def copy(self):\n",
    "        data1 = data.copy()\n",
    "        data2 = data.copy()\n",
    "    \n",
    "    def describe(self):\n",
    "        \n",
    "        return data.describe()\n",
    "        \n",
    "    def shape(self):\n",
    "        \n",
    "        #type(data)\n",
    "        print(data.axes)\n",
    "        #print(self.data.axes)\n",
    "        #print(\" ndim = \" + str(data.ndim))\n",
    "        print(\" Veri şekli = \" + str(data.shape))\n",
    "        print(\" Veri büyüklüğü = \" + str(data.size))\n",
    "        #type(data.values)\n",
    "    \n",
    "    def head(self,row = None):\n",
    "        \n",
    "        return data.head(5)\n",
    "        # print(data.tail(3))\n",
    "        \n",
    "    def hedef_degisken(self):\n",
    "        \n",
    "        print(\"**********************************\")\n",
    "        print(\" 90_target Değişkeninin incelenmesi\")\n",
    "        print(\"Ortalama: \" + str(data[\"90_target\"].mean()))\n",
    "        print(\"Dolu Gözlem Sayısı: \" + str(data[\"90_target\"].count())) \n",
    "        print(\"Maksimum Değer: \" + str(data[\"90_target\"].max()))\n",
    "        print(\"Minimum Değer: \" + str(data[\"90_target\"].min()))\n",
    "        print(\"Medyan: \" + str(data[\"90_target\"].median()))\n",
    "        print(\"Standart Sapma: \" + str(data[\"90_target\"].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERİ GÖRSELLEŞTİRME\n",
    "\n",
    "### Bu class içerisinde incelemek istediğimiz değişkenleri görselleştirerek daha yakından tanıma fırsatı buluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization():\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    def visual(self):\n",
    "        data[\"ind_109\"].value_counts().plot.barh().set_title(\"Job Değişkeninin Sınıf Frekansları\");\n",
    "    \n",
    "    def countplot(self):\n",
    "        sns.countplot(x=\"ind_109\", data=data, palette=\"bwr\")\n",
    "        plt.show()\n",
    "        \n",
    "    def probplot(self):\n",
    "        \n",
    "        import statsmodels.api as sm\n",
    "        import pylab\n",
    "        import scipy.stats as stats\n",
    "        stats.probplot(data[\"ind_18\"],dist = \"norm\" , plot = pylab) # normal probability plot\n",
    "        pylab.show()\n",
    "        \n",
    "    def scatterplot(self):\n",
    "        data.plot.scatter(\"90_target\",\"ind_18\");\n",
    "        \n",
    "    def distplot(self):\n",
    "        sns.distplot(data[\"90_target\"], kde = False);\n",
    "        \n",
    "    def pairplot(self):\n",
    "        \n",
    "        #sns.pairplot(data);\n",
    "        pass\n",
    "        \n",
    "    def pivotTable(self):\n",
    "        \n",
    "        # print(data.pivot_table(\"...\",index = \"...\",columns = \"...\"))\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İSTATİSTİK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stats():\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    def imports(self):\n",
    "        \n",
    "        import scipy.stats as stats\n",
    "        import statsmodels.stats.api as sms\n",
    "        import pylab\n",
    "        from scipy.stats.stats import pearsonr\n",
    "        import researchpy as rp\n",
    "        \n",
    "    \n",
    "    def table(self):\n",
    "        \n",
    "        print(rp.summary_cont(data[[\"ind_5\",\"ind_6\"]])) \n",
    "        \n",
    "        print(\"*******************************\")\n",
    "        \n",
    "        print(rp.summary_cat(data[\"ind_109\"]))\n",
    "        \n",
    "        print(\"*******************************\")\n",
    "        \n",
    "       \n",
    "        \n",
    "    def shapiro(self):\n",
    "        \n",
    "        import scipy.stats as stats\n",
    "        from scipy.stats import shapiro\n",
    "        test, p_value = shapiro(data[\"90_target\"])\n",
    "        \n",
    "        print(\"Varsayım kontrolünde pvalue = \" + str(p_value))\n",
    "        \n",
    "        \n",
    "        if p_value > 0.05:\n",
    "            print(\"Örnek dağılımı ile teorik normal dağılım arasında ist. ol. anl. bir fark. yoktur.\")\n",
    "        else:\n",
    "            print(\"Örnek dağılımı ile teorik normal dağılım arasında ist. ol. anl. bir fark. vardır.\")\n",
    "        \n",
    "        test_istatistigi, pvalue = stats.ttest_1samp(data[\"90_target\"], popmean = 10000)\n",
    "        print(\"pvalue = \" + str(pvalue))\n",
    "        \n",
    "        if pvalue > 0.05 :\n",
    "            print(\"H0 hipotezimiz reddedilemez.\")\n",
    "        else:\n",
    "            print(\"H0 hipotezimiz reddelir.\")   \n",
    "        \n",
    "        \n",
    "        \n",
    "    def qqplot(self):\n",
    "        import pylab\n",
    "        import scipy.stats as stats\n",
    "        stats.probplot(data[\"90_target\"], dist=\"norm\", plot=pylab)\n",
    "        pylab.show()\n",
    "        \n",
    "    def korelasyon_analiz(self):\n",
    "        \n",
    "        \n",
    "        data.plot.scatter(\"90_target\",\"ind_424\");\n",
    "\n",
    "        print(data[\"90_target\"].corr(data[\"ind_424\"])) # parametrik karşılığı\n",
    "        \n",
    "        # Hedef değişken 90_target için analiz\n",
    "        \n",
    "        print(data.corr()['90_target'].abs().sort_values(ascending=False))\n",
    "        \n",
    "        \n",
    "    def korelasyon_map(self):\n",
    "        \n",
    "        corr = data.corr()\n",
    "        # print(corr)\n",
    "        # sns.heatmap(corr, \n",
    "        #xticklabels=corr.columns.values,\n",
    "        #yticklabels=corr.columns.values)\n",
    "        \n",
    "        fig,ax = plt.subplots(figsize=(15, 15))\n",
    "        sns.heatmap(data.corr(), ax=ax, annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing():\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def copy_data(self):\n",
    "        \n",
    "        data2 = data.copy()\n",
    "        data3 = data.copy()\n",
    "        \n",
    "    def outlier(self):\n",
    "        \n",
    "        t_data = data.dropna() # Eksik gözlemleri sildik. Aykırı gözlemleri rahatça görebilmek için.\n",
    "        print(t_data.head())\n",
    "        \n",
    "        # Bir tane gözlemimi alıyorum.\n",
    "        data_target = t_data[\"90_target\"]\n",
    "        sns.boxplot(x = data_target);\n",
    "        \n",
    "        Q1 = data_target.quantile(0.25)\n",
    "        Q3 = data_target.quantile(0.75)\n",
    "        IQR = Q3-Q1\n",
    "       \n",
    "        \n",
    "        print(\" IQR = \" + str(Q3-Q1))\n",
    "        print(\" Alt Sınır = \" + str(Q1- 1.5*IQR))\n",
    "        print(\" Üst Sınır = \" + str(Q3 + 1.5*IQR))\n",
    "        print(data_target.median())\n",
    "       \n",
    "        # Daha sonra aykırı değeri Baskılama ve ya Ortalama yöntemi ile doldurma işlemleri\n",
    "    \n",
    "    def MissingValue(self):\n",
    "        \n",
    "        print(data.isnull().sum())\n",
    "        #print(data.isnull())\n",
    "        #print(data[data.isnull().any(axis = 1)]) # Eksik değer olan satırlara erişmek\n",
    "        \n",
    "        # Bir gözlemi örnek alıyorum.\n",
    "        # data[\"loan\"]\n",
    "        # data[\"loan\"].mean()\n",
    "        # print(data[\"loan\"].fillna(data[\"loan\"].mean())) # fillna doldurma işlemi için yapılıyor.\n",
    "        \n",
    "        # data.isna().values.any() #Kalan NaN değeri var mı kontrol etmek için\n",
    "     \n",
    "    def dropNa(self):\n",
    "        data.dropna(inplace = True) # tüm eksik gözlemlerin silinmesi\n",
    "        return data.isnull().sum()     \n",
    "    \n",
    "    def fillna(self):\n",
    "        \n",
    "        data.fillna(data.mean()[:],inplace = True) # eksik değerleri ortalama yöntemi ile doldurma\n",
    "        \n",
    "        # kategorik\n",
    "        \n",
    "        print(\" En sık tekrarlanan değişken:\" + str(data[\"ind_109\"].mode()[0]))\n",
    "        data[\"ind_109\"].fillna(data[\"job\"].mode()[0],inplace = True)\n",
    "        \n",
    "        return data.isnull().sum()\n",
    "        \n",
    "    def scale(self):\n",
    "        from sklearn.preprocessing import StandardScaler  \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.X_train)\n",
    "        self.X_train_scaled = scaler.transform(self.X_train)\n",
    "        self.X_test_scaled = scaler.transform(self.X_test)\n",
    "        \n",
    "    \n",
    "    def normalize(self):\n",
    "        \n",
    "        from sklearn import preprocessing\n",
    "        preprocessing.normalize(self.X)\n",
    "        \n",
    "        \n",
    "    def dummies(self):\n",
    "        \n",
    "        # Veri setinin hikayesini bilmediğim için şimdilik object değişkenleri siliyorum.\n",
    "        # Bu object değişkenler önemli değişkenler de olabilir.\n",
    "        \n",
    "        cat = pd.get_dummies(data[['ind_109']])\n",
    "        self.y = data[\"90_target\"]\n",
    "        self.X = data.drop([\"90_target\",\"50_target\",\"20_target\",\"ind_109\",\"ind_420\",\"ind_422\"],axis =1).astype(\"float64\")\n",
    "        self.X = pd.concat([self.X, cat[[\"ind_109_GREEN\",\"ind_109_RED\"]]])\n",
    "        return self.X.head(3)\n",
    "        \n",
    "        \n",
    "    def onhazirlik(self): # burada DUMMIES yapmazsak modele sokulacak target değişken ve çıkarılması gereken değişkenler \n",
    "        \n",
    "        \n",
    "        self.y = data[\"90_target\"]\n",
    "        self.X = data.drop([\"90_target\",\"50_target\",\"20_target\",\"ind_109\",\"ind_420\",\"ind_422\"],axis = 1)\n",
    "        \n",
    "        return self.X.head(3)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def train_test_split(self):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state = 42)\n",
    "    \n",
    "    \n",
    "    def pca(self):\n",
    "        \n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.preprocessing import scale \n",
    "        pca = PCA(4)\n",
    "        self.X_reduced_train = pca.fit_transform(scale(self.X_train))\n",
    "        self.X_reduced_test = pca.fit_transform(scale(self.X_test))\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        features = range(pca.n_components_)\n",
    "        plt.figure(figsize=(20,15))\n",
    "        plt.bar(features, pca.explained_variance_ratio_, color = 'black')\n",
    "        plt.xlabel('PCA Features')\n",
    "        plt.ylabel('variance%')\n",
    "        # plt.xticks(features)\n",
    "        \n",
    "        self.lm = LinearRegression()\n",
    "        self.pcr_model = lm.fit(self.X_reduced_train, self.y_train)\n",
    "        \n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        \n",
    "        self.y_pred = self.pcr_model.predict(self.X_reduced_train)\n",
    "        self.pcr_rmse_train = np.sqrt(mean_squared_error(self.y_train, self.y_pred))\n",
    "        print(\" TRAIN PCR RMSE:\"+ str(self.pcr_rmse_train))\n",
    "        \n",
    "        self.y_pred_test = pcr_model.predict(self.X_reduced_test)\n",
    "        self.pcr_rmse_test = np.sqrt(mean_squared_error(self.y_test, self.y_pred_test))\n",
    "        print(\" TEST PCR RMSE:\"+ str(self.pcr_rmse_test))\n",
    "        r_square_pcr = r2_score(y_test, y_pred)\n",
    "        print(\"r^2 PCR:\" + str(r_square_pcr))\n",
    "\n",
    "        \n",
    "        \n",
    "        return np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def lineer(self):\n",
    "        \n",
    "        self.X = data[\"ind_18\"]\n",
    "        self.y = data[\"90_target\"]\n",
    "        self.lm= sm.OLS(self.y,self.X) # burada normalite varsayımına gerek duymuyoruz.\n",
    "        self.model = self.lm.fit()\n",
    "        print(\"f_pvalue:\" + str(self.model.f_pvalue))\n",
    "        lineer_r = self.model.rsquared_adj\n",
    "        print(\"r square:\"  + str(self.model.rsquared_adj))\n",
    "        \n",
    "        self.model.fittedvalues[0:5]\n",
    "        # Artıklar ve önemi\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        self.mse = mean_squared_error(self.y, self.model.fittedvalues)\n",
    "        self.rmse = np.sqrt(self.mse)\n",
    "        print(\"rmse:\" + str(self.rmse))\n",
    "        \n",
    "        self.model.resid[0:10] # hatalar\n",
    "        plt.plot(self.model.resid) \n",
    "        \n",
    "        \n",
    "        return self.model.summary()\n",
    "        \n",
    "        # Modelin anlamlılığına ilişkin p value değeri. Çok küçükse model anlamlıdır.\n",
    "        # çok yüksek çıksaydı modele giren değişkenlerin hiçbir anlamı yok yani X'lerin bi etkisi yok gibi \n",
    "        # Hepsinin beta'sı sıfır gibi katsayıları yani..\n",
    "     \n",
    "    def multi_lineer(self):\n",
    "        \n",
    "        import seaborn as sns\n",
    "        self.lm = sm.OLS(self.y_train, self.X_train)\n",
    "        self.model = self.lm.fit()\n",
    "        self.influence = self.model.get_influence() \n",
    "        \n",
    "        self.resid_student = self.influence.resid_studentized_external \n",
    "        (cooks,p)=self.influence.cooks_distance\n",
    "        (dffits,p)=self.influence.dffits\n",
    "        self.leverage=self.influence.hat_matrix_diag\n",
    "        print('Leverag v.s. Studentized Residuals')\n",
    "        sns.regplot(self.leverage, self.model.resid_pearson, fit_reg=False) #hatalarımın dağılımını görüyorum.\n",
    "        self.rmse = np.sqrt(mean_squared_error(self.y_test, self.model.predict(self.X_test)))\n",
    "        print(\"rmse:\"+ str(self.rmse))\n",
    "        return self.model.summary().tables[1]\n",
    "    \n",
    "    def error_test(self):\n",
    "        \n",
    "        import seaborn as sns \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        advres = pd.concat([data , pd.Series(model.resid, name = 'resid'), pd.Series(model.predict(), name = \"predict\")], axis = 1)\n",
    "        sns.kdeplot(np.array(advres.resid), bw=10)\n",
    "        \n",
    "    def qqplot_error(self):\n",
    "        import statsmodels.api as sm\n",
    "        sm.qqplot(advres.resid)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def SVR(self):\n",
    "        from sklearn.svm import SVR\n",
    "        self.svr_model = SVR(\"linear\").fit(self.X_reduced_train, self.y_train)\n",
    "        self.y_pred = self.svr_model.predict(self.X_reduced_test)\n",
    "        self.rmse_svr = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\"SVR RMSE:\"+ str(self.rmse_svr))\n",
    "        \n",
    "        \n",
    "    def ModelTuningSVR(self):\n",
    "        \n",
    "        self.svr_params = {\"C\": np.arange(0.1,2,0.1)}\n",
    "        self.svr_cv_model = GridSearchCV(self.svr_model, self.svr_params, cv = 3,n_jobs = -1, verbose = 2).fit(self.X_reduced_train,self.y_train)\n",
    "\n",
    "        print(\"En iyi parametreler: \" + str(svr_cv_model.best_params_))\n",
    "        \n",
    "        self.svr_tuned = SVR(\"linear\", \n",
    "                        C = self.svr_cv_model.best_params_[\"C\"]).fit(self.X_reduced_train, self.y_train)\n",
    "        \n",
    "        self.y_pred = self.svr_tuned.predict(self.X_reduced_test)\n",
    "        self.rmse_svr_tuned = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        \n",
    "        print(\" TUNED SVR RMSE:\"+ str(self.rmse_svr_tuned))\n",
    "        \n",
    "    def RBF(self): \n",
    "        \n",
    "        self.svr_rbf = SVR(\"rbf\").fit(self.X_reduced_train, self.y_train)\n",
    "        self.y_pred = svr_rbf.predict(self.X_reduced_test)\n",
    "        self.rmse_rbf_svr = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\"RBF RMSE:\"+ str(self.rmse_rbf_svr))\n",
    "    \n",
    "    def ModelTuningRBF(self):\n",
    "        \n",
    "        self.svr_params = {\"C\": [0.1,0.4,5,15]}\n",
    "        self.svr_cv_model = GridSearchCV(self.svr_rbf,self.svr_params, cv = 3,n_jobs = -1, verbose = 2)\n",
    "        self.svr_cv_model.fit(self.X_reduced_train, self.y_train)\n",
    "        print(\"En iyi parametreler: \" + str(self.svr_cv_model.best_params_))\n",
    "        self.svr_tuned = SVR(\"rbf\", C = self.svr_cv_model.best_params_[\"C\"]).fit(self.X_reduced_train, self.y_train)\n",
    "        self.y_pred = self.svr_tuned.predict(self.X_reduced_test)\n",
    "\n",
    "        self.rmse_rbf_svr_tuned = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "         \n",
    "        print(\" TUNED RBF RMSE:\"+ str(self.rmse_svr_tuned))\n",
    "\n",
    "    \n",
    "    \n",
    "    def MLPR(self):\n",
    "        \n",
    "        from sklearn.neural_network import MLPRegressor\n",
    "        self.mlp_model = MLPRegressor(hidden_layer_sizes = (100,20)).fit(self.X_reduced_train, self.y_train)\n",
    "        self.y_pred = self.mlp_model.predict(self.X_reduced_test)\n",
    "        self.rmse_mlp = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\"MLPR RMSE:\"+ str(self.rmse_mlp))\n",
    "        \n",
    "    def ModelTuning_MLPR(self):\n",
    "        self.mlp_params = {'alpha': [0.1,0.02,0.005],\n",
    "                      'hidden_layer_sizes': [(20,20),(100,50,150),(300,200,150)],\n",
    "                      'activation': ['relu','logistic']}\n",
    "        self.mlp_cv_model = GridSearchCV(self.mlp_model, self.mlp_params, cv = 3,n_jobs = -1 , verbose =2)\n",
    "        self.mlp_cv_model.fit(self.X_reduced_train, self.y_train)\n",
    "        print(\"En iyi parametreler: \" + str(self.mlp_cv_model.best_params_))\n",
    "        \n",
    "        self.mlp_tuned = MLPRegressor(alpha = self.mlp_cv_model.best_params_[\"alpha\"] , hidden_layer_sizes = self.mlp_cv_model.best_params_[\"hidden_layer_sizes\"],\n",
    "                        activation = self.mlp_cv_model.best_params_[\"activation\"])\n",
    "        self.mlp_tuned.fit(self.X_reduced_train, self.y_train)\n",
    "        self.y_pred = self.mlp_tuned.predict(self.X_reduced_test)\n",
    "        self.rmse_mlp_tuned = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\" TUNED MLP RMSE:\"+ str(self.rmse_mlp_tuned))\n",
    "\n",
    "    \n",
    "    def gradientboost(self):\n",
    "        \n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        self.gbm_model = GradientBoostingRegressor()\n",
    "        self.gbm_model.fit(self.X_reduced_train, self.y_train)\n",
    "        # Tahmin\n",
    "        self.y_pred = self.gbm_model.predict(self.X_reduced_test)\n",
    "        self.rmse_gbm = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\"GBM RMSE:\"+ str(self.rmse_gbm))\n",
    "     \n",
    "    def ModelTuning_gradientboost(self):\n",
    "        \n",
    "        gbm_params = {'learning_rate': [0.01, 0.1, 0.2],\n",
    "                      'max_depth': [3, 5,50,100],\n",
    "                      'n_estimators': [200, 500, 1000],\n",
    "                      'subsample': [1,0.5,0.75],\n",
    "                     }\n",
    "        \n",
    "        self.gbm = GradientBoostingRegressor()\n",
    "        self.gbm_cv_model = GridSearchCV(self.gbm, self.gbm_params, cv = 2, n_jobs = -1, verbose = 2)\n",
    "        self.gbm_cv_model.fit(self.X_reduced_train, self.y_train)\n",
    "        print(\"En iyi parametreler: \" + str(self.gbm_cv_model.best_params_))\n",
    "        \n",
    "        self.gbm_tuned = GradientBoostingRegressor(learning_rate = self.bm_cv_model.best_params_[\"learning_rate\"],  \n",
    "                                                   max_depth = self.gbm_cv_model.best_params_[\"max_depth\"], \n",
    "                                                   n_estimators = self.gbm_cv_model.best_params_[\"n_estimators\"], \n",
    "                                                   subsample = self.gbm_cv_model.best_params_[\"subsample\"])\n",
    "\n",
    "        self.gbm_tuned = gbm_tuned.fit(self.X_reduced_train,self.y_train)\n",
    "        self.y_pred = gbm_tuned.predict(self.X_reduced_test)\n",
    "        self.rmse_gbm_tuned = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\" TUNED GBM RMSE:\"+ str(self.rmse_gbm_tuned))\n",
    "     \n",
    "    \n",
    "    def KNN(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.neighbors import KNeighborsRegressor\n",
    "        \n",
    "        self.knn_model = KNeighborsRegressor().fit(self.X_reduced_train, self.y_train)\n",
    "        \n",
    "        print(\"n_neighbors:\" + str(self.knn_model.n_neighbors))\n",
    "        print(\"effective_metric:\" + str(self.knn_model.effective_metric_))\n",
    "        self.y_pred = self.knn_model.predict(self.X_reduced_test)\n",
    "        self.rmse_knn = np.sqrt(mean_squared_error(self.y_test, self.y_pred))\n",
    "        print(\"KNN RMSE:\"+ str(self.rmse_knn))\n",
    "        \n",
    "    def ModelTuning_KNN(self):\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        \n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        self.knn_params = {'n_neighbors': np.arange(1,30,1)}\n",
    "        self.knn = KNeighborsRegressor()\n",
    "        self.knn_cv_model = GridSearchCV(self.knn, self.knn_params, cv = 3,n_jobs = -1, verbose = 2)\n",
    "        self.knn_cv_model.fit(self.X_reduced_train, self.y_train)\n",
    "        self.knn_cv_model.best_params_[\"n_neighbors\"]\n",
    "       \n",
    "\n",
    "        self.knn_tuned = KNeighborsRegressor(n_neighbors = self.knn_cv_model.best_params_[\"n_neighbors\"])\n",
    "        self.knn_tuned.fit(self.X_reduced_train, self.y_train)\n",
    "        self.rmse_knn_tuned = np.sqrt(mean_squared_error(self.y_test, self.knn_tuned.predict(self.X_reduced_test)))\n",
    "        print(\"KNN TUNED RMSE:\"+ str(self.rmse_knn_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÖDEV AMACI; PCA ile boyut düşürerek modeller uygulamak olduğu için object değişkenlerimden ind_109 'a dummy yapacağım.\n",
    "\n",
    "### PCA uygulamamızın amacı modellerin daha hızlı çalışmasını sağlamaktır. Daha güçlü bir bilgisayar da PCA yapmamak ve ya daha doğru bir şekilde PCA yaparak verisetini modellere sokmak daha doğru olacaktır.\n",
    "\n",
    "### Diğer 2 object değişken olarak gözüken değişkenlerimi ise yanlış etiketlendiği gerekçesi ile integer'a dönüştüreceğim ve ya direk drop edeceğim.\n",
    "\n",
    "### Bu çalışmada direk droplamayı tercih ediyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"HW_Data_Set.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = PreProcessing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_pvalue:1.1388842633054801e-05\n",
      "r square:0.002957781621115374\n",
      "rmse:36.92967855102184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>90_target</td>    <th>  R-squared:         </th> <td>   0.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   19.29</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 23 Aug 2020</td> <th>  Prob (F-statistic):</th> <td>1.14e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:00:47</td>     <th>  Log-Likelihood:    </th> <td> -31007.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6167</td>      <th>  AIC:               </th> <td>6.202e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6166</td>      <th>  BIC:               </th> <td>6.202e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ind_18</th> <td>   -0.1712</td> <td>    0.039</td> <td>   -4.393</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.095</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>31.967</td> <th>  Durbin-Watson:     </th> <td>   0.292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>1012.544</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.178</td> <th>  Prob(JB):          </th> <td>1.35e-220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.047</td> <th>  Cond. No.          </th> <td>    1.00</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              90_target   R-squared:                       0.003\n",
       "Model:                            OLS   Adj. R-squared:                  0.003\n",
       "Method:                 Least Squares   F-statistic:                     19.29\n",
       "Date:                Sun, 23 Aug 2020   Prob (F-statistic):           1.14e-05\n",
       "Time:                        18:00:47   Log-Likelihood:                -31007.\n",
       "No. Observations:                6167   AIC:                         6.202e+04\n",
       "Df Residuals:                    6166   BIC:                         6.202e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "ind_18        -0.1712      0.039     -4.393      0.000      -0.248      -0.095\n",
       "==============================================================================\n",
       "Omnibus:                       31.967   Durbin-Watson:                   0.292\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1012.544\n",
       "Skew:                           0.178   Prob(JB):                    1.35e-220\n",
       "Kurtosis:                       1.047   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre.lineer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devamını yetiştiremedim hocam kusura bakmayın.. Bilgisayarım çok yavaş. Geri kalan aşamalarda da aynı şekilde yapıp en son karşılaştırma grafiği koyacaktım.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
